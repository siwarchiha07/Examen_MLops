# üìñ Guide de Configuration Compl√®te

Ce guide d√©taille chaque √©tape de configuration du projet MLOps.

## √âtape 1 : Pr√©paration et Gestion du Code (Git)

### 1.1 Configuration locale Git

```bash
# V√©rifier la configuration actuelle
git config --global user.name
git config --global user.email

# Configurer si n√©cessaire
git config --global user.name "Votre Nom"
git config --global user.email "votre.email@example.com"
```

### 1.2 Initialisation du d√©p√¥t

```bash
# Initialiser Git (si pas d√©j√† fait)
git init

# Cr√©er les branches main et dev
git checkout -b main
git checkout -b dev

# Ou utiliser le script
# Windows: .\scripts\init_git.bat
# Linux/Mac: ./scripts/init_git.sh
```

### 1.3 Structure du d√©p√¥t

Votre projet doit avoir :
- ‚úÖ Branche `main` (stable, production)
- ‚úÖ Branche `dev` (d√©veloppement)
- ‚úÖ Fichier `.gitignore` (d√©j√† cr√©√©)

### 1.4 Workflow Git recommand√©

```bash
# Travailler sur dev
git checkout dev

# Faire vos modifications
# ...

# Commit
git add .
git commit -m "Description des changements"

# Quand pr√™t pour production
git checkout main
git merge dev
git push origin main
```

## √âtape 2 : Environnement et Conteneurisation (Docker)

### 2.1 Installation Docker

**Windows avec WSL Ubuntu:**

```bash
# Dans WSL Ubuntu
sudo apt-get update
sudo apt-get install docker.io docker-compose

# V√©rifier l'installation
docker --version
docker-compose --version
```

### 2.2 Structure Docker

Le projet contient :
- `dockerfile` : Image pour l'API FastAPI
- `docker-compose.yml` : Orchestration de tous les services

### 2.3 Services Docker

Le `docker-compose.yml` lance :
1. **PostgreSQL** : Base de donn√©es pour MLflow
2. **MinIO** : Stockage S3-compatible pour artifacts
3. **MLflow** : Serveur de tracking
4. **nlp-api** : API FastAPI pour l'inf√©rence

### 2.4 Commandes Docker

```bash
# Lancer tous les services
docker-compose up -d

# Voir les logs
docker-compose logs -f

# Arr√™ter les services
docker-compose down

# Rebuild apr√®s modification du code
docker-compose build
docker-compose up -d
```

## √âtape 3 : Versioning des Donn√©es (DVC)

### 3.1 Installation DVC

```bash
pip install dvc dvc-s3
```

### 3.2 Initialisation DVC

```bash
# Initialiser DVC dans le projet
dvc init

# Ajouter les fichiers de donn√©es
dvc add data/raw/github_repos.csv
dvc add data/raw/github_users.csv
dvc add data/processed/profiles_enriched.csv
dvc add data/processed/profiles_embeddings.npy
```

### 3.3 Configuration Remote (MinIO)

Une fois MinIO lanc√© via Docker :

```bash
# Ajouter MinIO comme remote
dvc remote add -d minio s3://dvc-data --local

# Configurer l'endpoint
dvc remote modify minio endpointurl http://localhost:9000 --local

# Configurer les credentials
dvc remote modify minio access_key_id minioadmin --local
dvc remote modify minio secret_access_key minioadmin --local
```

### 3.4 Utilisation DVC

```bash
# Push des donn√©es vers le remote
dvc push

# Pull des donn√©es depuis le remote
dvc pull

# Voir les fichiers track√©s
dvc list .

# Voir le statut
dvc status
```

## √âtape 4 : Pipeline et Tracking (ZenML & MLflow)

### 4.1 Installation ZenML

```bash
pip install zenml[mlflow] zenml[server]
```

### 4.2 Initialisation ZenML

```bash
# Initialiser ZenML
zenml init

# Configurer le tracker MLflow
zenml experiment-tracker register mlflow_tracker --flavor=mlflow \
    --tracking_uri=http://localhost:5000
```

### 4.3 Structure du Pipeline

Le pipeline ZenML (`pipelines/training_pipeline.py`) contient 4 √©tapes :

1. **`load_data()`** : Chargement des donn√©es brutes
2. **`preprocess_data()`** : Pr√©traitement et enrichissement
3. **`train_model()`** : G√©n√©ration des embeddings
4. **`evaluate_model()`** : Calcul des m√©triques

### 4.4 Ex√©cution du Pipeline

```bash
# Mode simple (entra√Ænement)
python pipelines/run_pipeline.py --mode train

# Mode optimisation (Optuna)
python pipelines/run_pipeline.py --mode optimize --n-trials 10
```

### 4.5 Tracking MLflow

MLflow track automatiquement :
- **Param√®tres** : model_name, batch_size, etc.
- **M√©triques** : MAE, Accuracy, etc.
- **Mod√®les** : Mod√®les versionn√©s sauvegard√©s

Acc√©der √† MLflow UI : http://localhost:5000

## √âtape 5 : Optimisation (Optuna)

### 5.1 Fonctionnement

Optuna teste automatiquement diff√©rents hyperparam√®tres :
- Mod√®les d'embedding (all-MiniLM-L6-v2, all-mpnet-base-v2, etc.)
- Tailles de batch (16, 32, 64)

### 5.2 Ex√©cution

```bash
python pipelines/run_pipeline.py --mode optimize --n-trials 20
```

### 5.3 R√©sultats

Les meilleurs param√®tres sont :
- Logg√©s dans MLflow
- Accessibles via `study.best_params`

## √âtape 6 : D√©ploiement et Inf√©rence

### 6.1 API Endpoints

L'API FastAPI expose plusieurs endpoints :

#### `/predict` - Pr√©diction NLP
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"text": "Python developer", "model_version": null}'
```

#### `/predict/similarity` - Similarit√©
```bash
curl -X POST "http://localhost:8000/predict/similarity" \
  -H "Content-Type: application/json" \
  -d '{
    "text1": "Python developer",
    "text2": "ML engineer"
  }'
```

#### `/models/info` - Informations mod√®les
```bash
curl http://localhost:8000/models/info
```

#### `/models/load/{version}` - Charger une version
```bash
curl -X POST "http://localhost:8000/models/load/abc123"
```

### 6.2 Versioning des Mod√®les

#### Mise √† jour v1 ‚Üí v2

1. **Entra√Æner un nouveau mod√®le** :
   ```bash
   python pipelines/run_pipeline.py --mode train
   ```

2. **Le mod√®le est automatiquement enregistr√© dans MLflow** avec un nouveau run_id

3. **Charger la nouvelle version** :
   ```bash
   # Via API
   curl -X POST "http://localhost:8000/models/load/{nouveau_run_id}"
   
   # Ou red√©marrer l'API (charge automatiquement la derni√®re version)
   docker-compose restart nlp-api
   ```

4. **Utiliser une version sp√©cifique** :
   ```bash
   curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "text": "Your text",
       "model_version": "run_id_specifique"
     }'
   ```

### 6.3 Mise √† jour sans interruption

L'API supporte le changement de version sans red√©marrage :
- Charger une nouvelle version via `/models/load/{version}`
- Sp√©cifier une version dans les requ√™tes `/predict`
- L'ancienne version reste disponible en cache

## ‚úÖ Checklist de Configuration

- [ ] Git configur√© avec nom et email
- [ ] Branches main et dev cr√©√©es
- [ ] `.gitignore` v√©rifi√©
- [ ] Docker et Docker Compose install√©s
- [ ] Services Docker lanc√©s (`docker-compose up -d`)
- [ ] DVC initialis√© (`dvc init`)
- [ ] Donn√©es ajout√©es √† DVC (`dvc add`)
- [ ] Remote DVC configur√© (MinIO)
- [ ] ZenML initialis√© (`zenml init`)
- [ ] MLflow tracker configur√©
- [ ] Pipeline test√© (`python pipelines/run_pipeline.py --mode train`)
- [ ] API accessible (http://localhost:8000/docs)
- [ ] MLflow UI accessible (http://localhost:5000)

## üéØ Prochaines √âtapes

1. Ajouter vos propres donn√©es dans `data/raw/`
2. Ex√©cuter le pipeline avec vos donn√©es
3. Optimiser les hyperparam√®tres avec Optuna
4. D√©ployer l'API en production
5. Mettre en place CI/CD (GitHub Actions, GitLab CI, etc.)

## üìö Ressources

- [Documentation Git](https://git-scm.com/doc)
- [Documentation Docker](https://docs.docker.com/)
- [Documentation DVC](https://dvc.org/doc)
- [Documentation ZenML](https://docs.zenml.io/)
- [Documentation MLflow](https://mlflow.org/docs/latest/index.html)
- [Documentation Optuna](https://optuna.org/)

