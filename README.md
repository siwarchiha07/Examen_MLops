# Projet MLOps - Talent Hunter NLP

Projet complet de MLOps avec Git, Docker, DVC, ZenML, MLflow, Optuna et d√©ploiement API.

## üìã Structure du Projet

```
.
‚îú‚îÄ‚îÄ api/                    # API FastAPI pour l'inf√©rence
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # Endpoints API avec versioning
‚îÇ   ‚îî‚îÄ‚îÄ model_manager.py   # Gestionnaire de mod√®les MLflow
‚îú‚îÄ‚îÄ data/                   # Donn√©es (g√©r√©es par DVC)
‚îÇ   ‚îú‚îÄ‚îÄ raw/               # Donn√©es brutes
‚îÇ   ‚îî‚îÄ‚îÄ processed/         # Donn√©es trait√©es
‚îú‚îÄ‚îÄ models/                 # Mod√®les entra√Æn√©s
‚îú‚îÄ‚îÄ pipelines/              # Pipelines ZenML
‚îÇ   ‚îú‚îÄ‚îÄ training_pipeline.py    # Pipeline d'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ optuna_optimization.py  # Optimisation hyperparam√®tres
‚îÇ   ‚îî‚îÄ‚îÄ run_pipeline.py          # Script d'ex√©cution
‚îú‚îÄ‚îÄ src/                    # Code source du projet
‚îú‚îÄ‚îÄ scripts/                # Scripts utilitaires
‚îú‚îÄ‚îÄ docker-compose.yml      # Orchestration Docker
‚îú‚îÄ‚îÄ dockerfile              # Image Docker pour l'API
‚îî‚îÄ‚îÄ requirements.txt        # D√©pendances Python
```

## üöÄ Installation et Configuration

### Pr√©requis

- Python 3.11+
- Docker et Docker Compose
- Git
- WSL Ubuntu (pour Windows)

### 1. Configuration Git

```bash
# V√©rifier la configuration Git
git config --global user.name "Votre Nom"
git config --global user.email "votre.email@example.com"

# Initialiser le d√©p√¥t (si pas d√©j√† fait)
git init
git branch -M main
git checkout -b dev

# Cr√©er les branches main et dev
git checkout -b main
git checkout -b dev
```

### 2. Installation des d√©pendances

```bash
# Cr√©er un environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows

# Installer les d√©pendances
pip install -r requirements.txt
```

### 3. Initialisation DVC

```bash
# Initialiser DVC
dvc init

# Ajouter les fichiers de donn√©es
dvc add data/raw/github_repos.csv
dvc add data/raw/github_users.csv
dvc add data/processed/profiles_enriched.csv
dvc add data/processed/profiles_embeddings.npy

# Configurer MinIO comme remote (apr√®s avoir lanc√© Docker)
dvc remote add -d minio s3://dvc-data --local
dvc remote modify minio endpointurl http://localhost:9000 --local
dvc remote modify minio access_key_id minioadmin --local
dvc remote modify minio secret_access_key minioadmin --local
```

### 4. Initialisation ZenML

```bash
# Initialiser ZenML
zenml init

# Configurer le store MLflow
zenml experiment-tracker register mlflow_tracker --flavor=mlflow \
    --tracking_uri=http://localhost:5000
```

## üê≥ D√©ploiement avec Docker

### Lancer tous les services

```bash
# Lancer MLflow, MinIO, PostgreSQL et l'API
docker-compose up -d

# V√©rifier les services
docker-compose ps
```

### Acc√©der aux interfaces

- **API FastAPI**: http://localhost:8000
- **Documentation API**: http://localhost:8000/docs
- **MLflow UI**: http://localhost:5000
- **MinIO Console**: http://localhost:9001 (minioadmin/minioadmin)

### Arr√™ter les services

```bash
docker-compose down
```

## üîÑ Pipeline ZenML

### Ex√©cution simple (entra√Ænement)

```bash
python pipelines/run_pipeline.py --mode train \
    --model-name "sentence-transformers/all-MiniLM-L6-v2" \
    --batch-size 32
```

### Optimisation avec Optuna

```bash
python pipelines/run_pipeline.py --mode optimize \
    --n-trials 10
```

### Ex√©cution directe du pipeline

```python
from pipelines.training_pipeline import nlp_training_pipeline

pipeline_instance = nlp_training_pipeline(
    model_name="sentence-transformers/all-MiniLM-L6-v2",
    batch_size=32
)
metrics = pipeline_instance.run()
```

## üåê API Endpoints

### Endpoints disponibles

#### 1. `/predict` - Pr√©diction NLP
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Python developer with ML experience",
    "model_version": null
  }'
```

#### 2. `/predict/similarity` - Similarit√© entre textes
```bash
curl -X POST "http://localhost:8000/predict/similarity" \
  -H "Content-Type: application/json" \
  -d '{
    "text1": "Python developer",
    "text2": "Machine learning engineer",
    "model_version": null
  }'
```

#### 3. `/models/info` - Informations sur les mod√®les
```bash
curl http://localhost:8000/models/info
```

#### 4. `/models/load/{version}` - Charger une version sp√©cifique
```bash
curl -X POST "http://localhost:8000/models/load/abc123def456"
```

#### 5. `/agent_search` - Recherche de talents (existant)
```bash
curl -X POST "http://localhost:8000/agent_search" \
  -H "Content-Type: application/json" \
  -d '{
    "job_description": "Looking for a Python developer",
    "top_k": 5
  }'
```

#### 6. `/health` - V√©rification de sant√©
```bash
curl http://localhost:8000/health
```

## üìä MLflow Tracking

### Acc√©der √† MLflow

1. Ouvrir http://localhost:5000
2. Voir les exp√©riences et runs
3. Comparer les m√©triques (Accuracy, MAE, etc.)
4. T√©l√©charger les mod√®les versionn√©s

### M√©triques track√©es

- `mae`: Erreur moyenne absolue
- `accuracy`: Pr√©cision (%)
- `num_profiles`: Nombre de profils trait√©s
- `embedding_dim`: Dimension des embeddings
- `avg_profile_length`: Longueur moyenne des profils

## üîß Versioning des Mod√®les

### Mise √† jour v1 ‚Üí v2

1. **Entra√Æner un nouveau mod√®le**:
   ```bash
   python pipelines/run_pipeline.py --mode train
   ```

2. **Le mod√®le est automatiquement enregistr√© dans MLflow** avec un nouveau run_id

3. **Charger la nouvelle version dans l'API**:
   ```bash
   # Option 1: Via l'endpoint API
   curl -X POST "http://localhost:8000/models/load/{nouveau_run_id}"
   
   # Option 2: Red√©marrer l'API (charge automatiquement la derni√®re version)
   docker-compose restart nlp-api
   ```

4. **Utiliser une version sp√©cifique**:
   ```bash
   curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "text": "Your text here",
       "model_version": "run_id_specifique"
     }'
   ```

## üìù Workflow Complet

### 1. D√©veloppement (branche dev)

```bash
git checkout dev

# Faire des modifications
# Tester localement
python pipelines/run_pipeline.py --mode train

# Commit
git add .
git commit -m "Nouvelle fonctionnalit√©"
```

### 2. Entra√Ænement et tracking

```bash
# Lancer le pipeline avec tracking MLflow
python pipelines/run_pipeline.py --mode train

# Ou optimiser les hyperparam√®tres
python pipelines/run_pipeline.py --mode optimize --n-trials 20
```

### 3. Versioning des donn√©es

```bash
# Ajouter de nouvelles donn√©es
dvc add data/raw/nouvelles_donnees.csv

# Push vers le remote
dvc push
```

### 4. D√©ploiement

```bash
# Merge vers main
git checkout main
git merge dev

# Build et d√©ploiement Docker
docker-compose build
docker-compose up -d
```

## üß™ Tests

### Tester l'API

```bash
# Test de sant√©
curl http://localhost:8000/health

# Test de pr√©diction
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"text": "test"}'
```

### Tester le pipeline

```bash
python pipelines/run_pipeline.py --mode train
```

## üìö Documentation Additionnelle

- [Guide DVC](README_DVC.md) - Versioning des donn√©es
- [Documentation MLflow](https://mlflow.org/docs/latest/index.html)
- [Documentation ZenML](https://docs.zenml.io/)
- [Documentation FastAPI](https://fastapi.tiangolo.com/)

## üêõ D√©pannage

### MLflow ne d√©marre pas

```bash
# V√©rifier les logs
docker-compose logs mlflow

# Red√©marrer les services
docker-compose restart mlflow postgres
```

### Erreur de connexion √† MinIO

```bash
# V√©rifier que MinIO est d√©marr√©
docker-compose ps minio

# V√©rifier les credentials dans docker-compose.yml
```

### Mod√®le non trouv√© dans MLflow

- V√©rifier que le pipeline a bien √©t√© ex√©cut√©
- V√©rifier l'URI MLflow dans les variables d'environnement
- Consulter les logs: `docker-compose logs mlflow`

## üìÑ Licence

Ce projet est un projet acad√©mique pour le cours MLOps.

